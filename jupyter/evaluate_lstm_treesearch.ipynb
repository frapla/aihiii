{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "from itertools import product\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "import IPython\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import seaborn as sns\n",
    "import textalloc as ta\n",
    "from seaborn._statistics import LetterValues\n",
    "from tqdm import tqdm\n",
    "\n",
    "NOTEBOOK_PATH: Path = Path(IPython.extract_module_locals()[1][\"__vsc_ipynb_file__\"])\n",
    "PROJECT_DIR: Path = NOTEBOOK_PATH.parent.parent\n",
    "sys.path.append(str(PROJECT_DIR))\n",
    "import src.utils.custom_log as custom_log\n",
    "import src.utils.json_util as json_util\n",
    "from src._StandardNames import StandardNames\n",
    "from src.load.LoadForClassification import RENAMER, LoadForClassification\n",
    "from src.mcdm.GetRankingFromExperiments import GetRankingFromExperiments\n",
    "from src.mcdm.ReadAlternatives import ReadAlternative\n",
    "from src.utils.PathChecker import PathChecker\n",
    "from src.utils.set_rcparams import set_rcparams\n",
    "\n",
    "os.chdir(PROJECT_DIR)\n",
    "set_rcparams()\n",
    "\n",
    "LOG: logging.Logger = logging.getLogger(__name__)\n",
    "custom_log.init_logger(log_lvl=logging.INFO)\n",
    "LOG.info(\"Log start, project directory is %s (exist: %s)\", PROJECT_DIR, PROJECT_DIR.is_dir())\n",
    "\n",
    "CHECK: PathChecker = PathChecker()\n",
    "STR: StandardNames = StandardNames()\n",
    "\n",
    "FIG_DIR: Path = CHECK.check_directory(PROJECT_DIR / \"reports\" / \"figures\", exit=False)\n",
    "FIG_DIR /= NOTEBOOK_PATH.stem\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "LOG.info(\"Figure directory is %s (exist: %s)\", FIG_DIR, FIG_DIR.is_dir())\n",
    "\n",
    "EXP_DIR:Path = CHECK.check_directory(PROJECT_DIR / \"experiments\", exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH: float = 448.13095 / 72 -0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALTERNATIVES: pd.DataFrame = ReadAlternative(b_path=EXP_DIR, search_pattern=\"*_lstm_treesearch_*\").get_data()\n",
    "ALTERNATIVES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALTERNATIVES.drop(columns=[c for c in ALTERNATIVES.columns if int(c.split(\"-\")[1]) >= 11], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_factors():\n",
    "    factors = {}\n",
    "    for alternative in ALTERNATIVES.columns:\n",
    "        f_path = EXP_DIR / alternative / STR.fname_para\n",
    "        LOG.info(\"Reading factors from %s\", f_path)\n",
    "        paras = json_util.load(f_path)\n",
    "        factors[alternative] = paras[STR.pipeline]\n",
    "        for key in (\n",
    "            \"feature_extractor_path\",\n",
    "            \"plot_model\",\n",
    "            \"feature_extractor_path\",\n",
    "            \"start_early_stopping_from_n_epochs\",\n",
    "            \"max_epochs\",\n",
    "            \"patience_factor\",\n",
    "        ):\n",
    "            if key in factors[alternative]:\n",
    "                del factors[alternative][key]\n",
    "        factors[alternative][STR.perc] = paras[STR.perc][STR.target][0]\n",
    "        factors[alternative][\"ai_in\"] = paras[STR.data][STR.input][STR.feature]\n",
    "\n",
    "    factors = pd.DataFrame(factors).T\n",
    "    factors.index.name = STR.alternatives\n",
    "    factors.columns.name = \"Factors\"\n",
    "\n",
    "    for col in factors.columns:\n",
    "        if isinstance(factors[col].iloc[0], list):\n",
    "            factors[col] = [tuple(q) for q in factors[col]]\n",
    "\n",
    "    return factors\n",
    "\n",
    "\n",
    "FACTORS:pd.DataFrame = get_factors()\n",
    "FACTORS = FACTORS[FACTORS[STR.perc].eq(95)].copy()\n",
    "ALTERNATIVES = ALTERNATIVES[FACTORS.index].copy()\n",
    "FACTORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rankings() -> pd.DataFrame:\n",
    "    r = GetRankingFromExperiments(b_path=EXP_DIR, files=FACTORS.index.to_list())\n",
    "    r.get_data()\n",
    "    return r.get_ranking()\n",
    "\n",
    "\n",
    "RANKINGS: pd.DataFrame = get_rankings()\n",
    "RANKINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_a_plot():\n",
    "    groups = set([x[36:] for x in sorted(ALTERNATIVES.columns) if not x.endswith(\"false\")])\n",
    "    groups = set([x for x in groups if \"perc\" not in x])\n",
    "    fig, (axl1, axl2, ax1) = plt.subplots(\n",
    "        nrows=3,\n",
    "        height_ratios=[0.1, 0.1, 1],\n",
    "        layout=\"constrained\",\n",
    "    )\n",
    "    ax2 = ax1.twinx()\n",
    "    criteria = (\"us_MLmetric\", \"setup_training_comp_time_metamodel\")\n",
    "    naming = {\n",
    "        \"us_MLmetric\": \"R² on Test Set\",\n",
    "        \"setup_training_comp_time_metamodel\": \"$\\O$ Computation Time Training per Fit [min]\",\n",
    "    }\n",
    "\n",
    "    j = 0\n",
    "    stored = {}\n",
    "    for criterion, ax in zip(criteria, (ax1, ax2)):\n",
    "        data = ALTERNATIVES.loc[[criterion]].T.sort_index()\n",
    "        data[\"IDX\"] = range(data.shape[0])\n",
    "        stored[criterion] = data\n",
    "\n",
    "        if criterion == criteria[0]:\n",
    "            data[criterion] -= 1\n",
    "            data[criterion] *= -1\n",
    "        else:\n",
    "            data[criterion] /= 60\n",
    "            data[criterion] /= 6\n",
    "\n",
    "        ax.plot(data[\"IDX\"], data[criterion], c=\"black\", alpha=0.1)\n",
    "\n",
    "        for group in sorted(groups):\n",
    "            idx = [x for x in data.index if x[36:] in group]\n",
    "\n",
    "            ax.scatter(\n",
    "                data.loc[idx, \"IDX\"],\n",
    "                data.loc[idx, criterion],\n",
    "                label=group,\n",
    "                s=60,\n",
    "                marker=\"o\" if criterion == criteria[0] else \"x\",\n",
    "            )\n",
    "\n",
    "            if criterion == criteria[0]:\n",
    "                for i in idx:\n",
    "                    try:\n",
    "                        ax.annotate(\n",
    "                            text=FACTORS.loc[i, group],\n",
    "                            xy=(data.loc[i, \"IDX\"], data.loc[i, criterion]),\n",
    "                            xytext=(data.loc[i, \"IDX\"], 0.003 + data.loc[i, criterion]),  # 0.915 + j * 0.0008),\n",
    "                            arrowprops=dict(ec=\"black\", lw=1, arrowstyle=\"-\", alpha=0.6),\n",
    "                            ha=\"center\",\n",
    "                            bbox=dict(boxstyle=\"round\", fc=\"grey\", ec=\"grey\", alpha=0.2),\n",
    "                            rotation=90,\n",
    "                        )\n",
    "                        j += 1\n",
    "                    except KeyError:\n",
    "                        pass\n",
    "\n",
    "        ax.set_ylabel(naming[criterion])\n",
    "\n",
    "    axl1.legend(*ax1.get_legend_handles_labels(), loc=\"center\", ncol=4, title=naming[criteria[0]])\n",
    "    axl1.axis(\"off\")\n",
    "    axl2.legend(*ax2.get_legend_handles_labels(), loc=\"center\", ncol=4, title=\" \".join(naming[criteria[1]].split()[:-1]))\n",
    "    axl2.axis(\"off\")\n",
    "\n",
    "    ax1.grid()\n",
    "    ax1.set_xticks(range(data.shape[0] - 2))\n",
    "    ax1.set_axisbelow(True)\n",
    "    ax1.set_xlim([-0.5, 18.5])\n",
    "    ax1.set_xlabel(\"Iteration\")\n",
    "    ax1.set_ylim([0.9, 0.93])\n",
    "    # ax2.set_ylim([0, 82000])\n",
    "\n",
    "    fig.set_figwidth(WIDTH)\n",
    "    fig.set_figheight(WIDTH * 0.72)\n",
    "    fig.savefig(FIG_DIR / \"lstm_tournament.pdf\")\n",
    "\n",
    "    return stored\n",
    "\n",
    "\n",
    "STORED = make_a_plot()\n",
    "STORED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_duplicates(criterion: str = \"us_MLmetric\"):\n",
    "    c = list(FACTORS.columns)\n",
    "    c = FACTORS.reset_index().set_index(c).sort_index()\n",
    "    w = []\n",
    "\n",
    "    grouper = {}\n",
    "    used = set()\n",
    "    for qq, idx in enumerate(c.index):\n",
    "        if idx in used:\n",
    "            continue\n",
    "        used.add(idx)\n",
    "        n = c.loc[idx]\n",
    "        if n.shape[0] > 1:\n",
    "            for i in range(n.shape[0]):\n",
    "                w.append(\n",
    "                    (\n",
    "                        ALTERNATIVES.loc[criterion, n.iloc[i]].to_list()[0],\n",
    "                        str(i),\n",
    "                        str(qq),\n",
    "                        STORED[criterion].loc[n.iloc[i][\"Alternatives\"], \"IDX\"],\n",
    "                    )\n",
    "                )\n",
    "            grouper[qq] = idx\n",
    "\n",
    "    w = pd.DataFrame(w, columns=[criterion, \"Repetition\", \"Group\", \"IDX\"])\n",
    "    w[criterion] -= 1\n",
    "    w[criterion] *= -1\n",
    "    grouper = pd.DataFrame(grouper, index=c.index.names).T\n",
    "\n",
    "    display(grouper)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(WIDTH, 0.3 * WIDTH))\n",
    "    plots = sns.barplot(\n",
    "        w,\n",
    "        y=criterion,\n",
    "        x=\"Group\",\n",
    "        hue=\"Repetition\",\n",
    "        legend=False,\n",
    "        ax=ax,\n",
    "        gap=0.1,\n",
    "    )\n",
    "    ax.set_ylim([0.9, 0.93])\n",
    "    ax.set_ylabel(\"R² on Test Set\")\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_xticklabels([])\n",
    "    ax.grid()\n",
    "    ax.set_axisbelow(True)\n",
    "\n",
    "    q = w.set_index(criterion)\n",
    "    for bar in plots.patches:\n",
    "        plots.annotate(\n",
    "            q.loc[bar.get_height(), \"IDX\"],\n",
    "            (bar.get_x() + bar.get_width() / 2, bar.get_height()),\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            xytext=(0, 8),\n",
    "            textcoords=\"offset points\",\n",
    "        )\n",
    "\n",
    "    fig.savefig(FIG_DIR / f\"lstm_tournament_duplicates_{criterion}.pdf\")\n",
    "\n",
    "\n",
    "get_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_duplicates(\"setup_training_comp_time_metamodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
