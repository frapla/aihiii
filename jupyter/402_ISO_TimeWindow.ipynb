{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "from itertools import product\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Literal, Optional, Tuple, Union\n",
    "from sklearn.metrics import  r2_score\n",
    "import plotly.express as px\n",
    "import scipy\n",
    "from tqdm import tqdm\n",
    "import IPython\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "from matplotlib.axes import Axes as Axes\n",
    "import logging\n",
    "from time import perf_counter\n",
    "\n",
    "NOTEBOOK_PATH:Path = Path(IPython.extract_module_locals()[1][\"__vsc_ipynb_file__\"])\n",
    "PROJECT_DIR:Path = NOTEBOOK_PATH.parent.parent\n",
    "sys.path.append(str(PROJECT_DIR))\n",
    "import src.utils.custom_log as custom_log\n",
    "from src.utils.PathChecker import PathChecker\n",
    "from src.utils.iso18571 import rating_iso_18571_short\n",
    "from src.utils.set_rcparams import set_rcparams\n",
    "from src._StandardNames import StandardNames\n",
    "\n",
    "os.chdir(PROJECT_DIR)\n",
    "LOG:logging.Logger = logging.getLogger(__name__)\n",
    "\n",
    "custom_log.init_logger(log_lvl=logging.INFO)\n",
    "LOG.info(\"Log initialized\")\n",
    "\n",
    "set_rcparams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STR: StandardNames = StandardNames()\n",
    "\n",
    "DATA_DIR = PathChecker().check_directory(path=PROJECT_DIR / \"data\" / \"doe\" / \"doe_big_grid_20230922_154140\")\n",
    "CHANNEL_FILE = PathChecker().check_file(path=DATA_DIR / STR.fname_channels)\n",
    "FIG_DIR = PROJECT_DIR / \"reports\" / \"figures\" / NOTEBOOK_PATH.stem\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PathChecker().check_directory(path=FIG_DIR)\n",
    "\n",
    "RELEVANT_CHANNELS: List[str] = [\n",
    "    \"03HEADLOC0OCCUDSXD\",\n",
    "    \"03HEADLOC0OCCUDSYD\",\n",
    "    \"03HEADLOC0OCCUDSZD\",\n",
    "    \"03HEAD0000OCCUACXD\",\n",
    "    \"03HEAD0000OCCUACYD\",\n",
    "    \"03HEAD0000OCCUACZD\",\n",
    "    \"03CHSTLOC0OCCUDSXD\",\n",
    "    \"03CHSTLOC0OCCUDSYD\",\n",
    "    \"03CHSTLOC0OCCUDSZD\",\n",
    "    \"03CHST0000OCCUDSXD\",\n",
    "    \"03CHST0000OCCUACXD\",\n",
    "    \"03CHST0000OCCUACYD\",\n",
    "    \"03CHST0000OCCUACZD\",\n",
    "    \"03PELVLOC0OCCUDSXD\",\n",
    "    \"03PELVLOC0OCCUDSYD\",\n",
    "    \"03PELVLOC0OCCUDSZD\",\n",
    "    \"03PELV0000OCCUACXD\",\n",
    "    \"03PELV0000OCCUACYD\",\n",
    "    \"03PELV0000OCCUACZD\",\n",
    "    \"03NECKUP00OCCUFOXD\",\n",
    "    \"03NECKUP00OCCUFOZD\",\n",
    "    \"03NECKUP00OCCUMOYD\",\n",
    "    \"03FEMRRI00OCCUFOZD\",\n",
    "    \"03FEMRLE00OCCUFOZD\",\n",
    "]\n",
    "\n",
    "TIME: np.ndarray = np.linspace(0, 140, 1401)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(\n",
    "    file: Path = CHANNEL_FILE,\n",
    "    columns: List[str] = RELEVANT_CHANNELS,\n",
    "    percentiles: List[int] = [5],\n",
    "    sim_ids: Optional[List[int]] = None,\n",
    ") -> pd.DataFrame:\n",
    "    LOG.info(\"Read data from %s\", file)\n",
    "    filters = [(STR.perc, \"in\", percentiles)]\n",
    "    if sim_ids is not None:\n",
    "        filters.append((STR.id, \"in\", sim_ids))\n",
    "\n",
    "    db = pd.read_parquet(path=file, columns=columns, filters=filters).droplevel(STR.perc).apply(pd.to_numeric, downcast=\"float\")\n",
    "\n",
    "    LOG.info(\"Got data with shape %s\", db.shape)\n",
    "\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_channels(channels: List[str] = RELEVANT_CHANNELS, percentiles: List[int] = [95]):\n",
    "    LOG.info(\"Read data\")\n",
    "    db: pd.DataFrame = read_data(percentiles=percentiles)\n",
    "\n",
    "    LOG.info(\"Calculate percentiles\")\n",
    "    quantile = db.groupby(STR.time).quantile((0.05, 0.25, 0.5, 0.75, 0.95))\n",
    "\n",
    "    LOG.info(\"Plot data\")\n",
    "    for channel in tqdm(channels):\n",
    "        # init\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "        # plot single signals\n",
    "        for idx in db.index.get_level_values(STR.id).unique():\n",
    "            ax.plot(TIME, db.loc[(slice(None), idx), channel], alpha=0.8)\n",
    "\n",
    "        # plot percentiles\n",
    "        ax.plot(TIME, quantile.loc[(slice(None), 0.50), channel], label=\"Median\", ls=\"-\", c=\"black\", lw=2)\n",
    "        ax.plot(TIME, quantile.loc[(slice(None), 0.25), channel], label=\"IQR\", ls=\"--\", c=\"black\", lw=2)\n",
    "        ax.plot(TIME, quantile.loc[(slice(None), 0.05), channel], label=\"Percentile 5-95\", ls=\":\", c=\"black\", lw=2)        \n",
    "        ax.plot(TIME, quantile.loc[(slice(None), 0.75), channel], ls=\"--\", c=\"black\", lw=2)\n",
    "        ax.plot(TIME, quantile.loc[(slice(None), 0.95), channel], ls=\":\", c=\"black\", lw=2)\n",
    "\n",
    "        # style\n",
    "        ax.legend()\n",
    "        ax.set_title(f\"HIII {percentiles}\")\n",
    "        ax.set_ylabel(channel)\n",
    "        ax.set_xlabel(\"Time [ms]\")\n",
    "        ax.grid()\n",
    "\n",
    "        fig.savefig(FIG_DIR / f\"all_ids_{channel}_perc_{'_'.join([str(per) for per in percentiles])}.png\")\n",
    "        plt.close(fig)\n",
    "\n",
    "    LOG.info(\"Done\")\n",
    "\n",
    "\n",
    "full_channels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def some_isos(channels: List[str] = RELEVANT_CHANNELS, percentiles: List[int] = [95]) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    LOG.info(\"Read data\")\n",
    "    db: pd.DataFrame = read_data(percentiles=percentiles)\n",
    "\n",
    "    LOG.info(\"Calculate percentiles\")\n",
    "    quantile = db.groupby(STR.time).quantile((0.05, 0.25, 0.5, 0.75, 0.95))\n",
    "    del db\n",
    "\n",
    "    LOG.info(\"Calculate\")\n",
    "    cases = list(product(channels, (0.05, 0.25, 0.75, 0.95), ((0, 140), (20, 120), (40, 120), (60, 120), (40, 100), (60, 100))))\n",
    "    ratings = defaultdict(lambda: defaultdict(dict))\n",
    "    r2s = defaultdict(lambda: defaultdict(dict))\n",
    "    for channel, quant, t_range in tqdm(cases):\n",
    "        # data\n",
    "        signal_ref = quantile.loc[(slice(*t_range), quant), channel].to_numpy()\n",
    "        signal_comp = quantile.loc[(slice(*t_range), 0.5), channel].to_numpy()\n",
    "\n",
    "        # iso\n",
    "        ratings[channel][quant][t_range] = rating_iso_18571_short(signal_ref=signal_ref, signal_comp=signal_comp)\n",
    "\n",
    "        # r2\n",
    "        r2s[channel][quant][t_range] = r2_score(y_true=signal_ref, y_pred=signal_comp)\n",
    "        r2s[channel][quant][t_range] = r2s[channel][quant][t_range] if r2s[channel][quant][t_range] > 0 else 0\n",
    "\n",
    "    LOG.info(\"Convert to DataFrame\")\n",
    "    ratings = pd.DataFrame.from_dict({(i, j): ratings[i][j] for i in ratings.keys() for j in ratings[i].keys()}, orient=\"index\")\n",
    "    ratings.index.names = [\"channel\", \"quantile\"]\n",
    "\n",
    "    r2s = pd.DataFrame.from_dict({(i, j): r2s[i][j] for i in r2s.keys() for j in r2s[i].keys()}, orient=\"index\")\n",
    "    r2s.index.names = [\"channel\", \"quantile\"]\n",
    "\n",
    "    LOG.info(\"Done\")\n",
    "\n",
    "    return ratings, r2s\n",
    "\n",
    "\n",
    "RATINGS, R2 = some_isos()\n",
    "RATINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(RATINGS.groupby(\"quantile\").median())\n",
    "display(R2.groupby(\"quantile\").median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(RATINGS.groupby(\"quantile\").min())\n",
    "display(R2.groupby(\"quantile\").min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(RATINGS.groupby(\"quantile\").max())\n",
    "display(R2.groupby(\"quantile\").max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = [\n",
    "    display(pd.concat([RATINGS.loc[(ch, slice(None)), :], R2.loc[(ch, slice(None)), :]], axis=1))\n",
    "    for ch in RATINGS.index.get_level_values(\"channel\").unique()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import resample\n",
    "import matplotlib.colors as mcolors\n",
    "from scipy.interpolate import CubicSpline\n",
    "\n",
    "\n",
    "def resampler(n_samples=5, channels: List[str] = RELEVANT_CHANNELS, percentiles: List[int] = [95]):\n",
    "    LOG.info(\"Read data\")\n",
    "    cs = sorted(mcolors.TABLEAU_COLORS.values())\n",
    "    t1 = np.linspace(0, 140, 1401)\n",
    "    t2 = np.linspace(0, 140, 50)\n",
    "    rng = np.random.default_rng()\n",
    "    ids = list(rng.integers(low=0, high=3124, size=n_samples))\n",
    "    db: pd.DataFrame = read_data(percentiles=percentiles, sim_ids=ids)\n",
    "\n",
    "    db_ = np.array(np.vsplit(db, n_samples))\n",
    "\n",
    "    db_resample = CubicSpline(x=t1, y=db_, axis=1)(t2)\n",
    "\n",
    "    db_back_sampled = CubicSpline(x=t2, y=db_resample, axis=1)(t1)\n",
    "    LOG.info(\"Resample from %s to %s and back to %s\", db_.shape, db_resample.shape, db_back_sampled.shape)\n",
    "\n",
    "    for idx, channel in enumerate(channels):\n",
    "        print(channel, np.sum(np.abs(db_[:, :, idx]-db_back_sampled[:, :, idx]))/(np.max(db_[:, :, idx])-np.min(db_[:, :, idx])))\n",
    "\n",
    "    LOG.info(\"Done\")\n",
    "\n",
    "\n",
    "resampler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy.interpolate import CubicSpline\n",
    "\n",
    "class MyDenseLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_outputs):\n",
    "        super(MyDenseLayer, self).__init__()\n",
    "        self.num_outputs = num_outputs\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        print(\"###\", input_shape)\n",
    "        pass\n",
    "\n",
    "    def call(self, inputs):\n",
    "        t1 = np.linspace(0, 140, 1401)\n",
    "        t2 = np.linspace(0, 140, self.num_outputs)\n",
    "\n",
    "        db_resample = CubicSpline(x=t1, y=inputs, axis=1)(t2)\n",
    "\n",
    "        return db_resample\n",
    "    \n",
    "MyDenseLayer(num_outputs=50)(np.random.random((100, 1401, 25))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inter(inputs, num_outputs):\n",
    "    t1 = np.linspace(0, 140, 1401)\n",
    "    t2 = np.linspace(0, 140, num_outputs)\n",
    "\n",
    "    return CubicSpline(x=t1, y=inputs, axis=1)(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter\n",
    "d = np.random.random((6553, 1401, 43))\n",
    "print(d.shape)\n",
    "\n",
    "tic = perf_counter()\n",
    "_ = inter(d, 50)\n",
    "print(perf_counter()-tic)\n",
    "\n",
    "tic = perf_counter()\n",
    "_ = MyDenseLayer(num_outputs=50)(d)\n",
    "print(perf_counter()-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy.interpolate import CubicSpline\n",
    "\n",
    "class MyDenseLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_outputs):\n",
    "        super(MyDenseLayer, self).__init__()\n",
    "        self.num_outputs = num_outputs\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        print(\"###\", input_shape)\n",
    "        pass\n",
    "\n",
    "    def call(self, inputs):\n",
    "        t1 = np.linspace(0, 140, 1401)\n",
    "        t2 = np.linspace(0, 140, self.num_outputs)\n",
    "\n",
    "        db_resample = CubicSpline(x=t1, y=inputs, axis=1)(t2)\n",
    "\n",
    "        return db_resample\n",
    "    \n",
    "MyDenseLayer(num_outputs=50)(np.random.random((100, 1401, 25))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
