{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "from itertools import product\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "import IPython\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import pyarrow.parquet as pq\n",
    "import seaborn as sns\n",
    "import textalloc as ta\n",
    "from IPython.display import display\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix, f1_score, precision_score, r2_score, recall_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "NOTEBOOK_PATH: Path = Path(IPython.extract_module_locals()[1][\"__vsc_ipynb_file__\"])\n",
    "PROJECT_DIR: Path = NOTEBOOK_PATH.parent.parent\n",
    "sys.path.append(str(PROJECT_DIR))\n",
    "import src.utils.custom_log as custom_log\n",
    "import src.utils.json_util as json_util\n",
    "from src._StandardNames import StandardNames\n",
    "from src.evaluate._Data import Data\n",
    "from src.load.LoadForClassification import RENAMER, LoadForClassification\n",
    "from src.utils.PathChecker import PathChecker\n",
    "from src.utils.set_rcparams import set_rcparams\n",
    "\n",
    "os.chdir(PROJECT_DIR)\n",
    "set_rcparams()\n",
    "\n",
    "LOG: logging.Logger = logging.getLogger(__name__)\n",
    "custom_log.init_logger(log_lvl=logging.INFO)\n",
    "LOG.info(\"Log start, project directory is %s (exist: %s)\", PROJECT_DIR, PROJECT_DIR.is_dir())\n",
    "\n",
    "CHECK: PathChecker = PathChecker()\n",
    "STR: StandardNames = StandardNames()\n",
    "\n",
    "FIG_DIR: Path = CHECK.check_directory(PROJECT_DIR / \"reports\" / \"figures\", exit=False)\n",
    "FIG_DIR /= NOTEBOOK_PATH.stem\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "LOG.info(\"Figure directory is %s (exist: %s)\", FIG_DIR, FIG_DIR.is_dir())\n",
    "\n",
    "DATA_DIR: Path = CHECK.check_directory(PROJECT_DIR / \"data\" / \"doe\" / \"doe_sobol_20240705_194200\", exit=False)\n",
    "INJ_FPATH: Path = CHECK.check_file(DATA_DIR / STR.fname_injury_crit, exit=False)\n",
    "CLASSES_FPATHS: Dict[int, Path] = {\n",
    "    i: CHECK.check_file(DATA_DIR / f\"{INJ_FPATH.stem}_classes_{i}.parquet\", exit=False) for i in (2, 3, 5, 7)\n",
    "}\n",
    "CHANNELS_FPATH: Path = CHECK.check_file(DATA_DIR / STR.fname_channels, exit=False)\n",
    "J_PATH: Path = CHECK.check_file(DATA_DIR / STR.fname_dropped_ids, exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(J_PATH) as f:\n",
    "    DROPPED_IDS = {int(k):set(i) for k,i in json.load(f).items()}\n",
    "DROPPED_IDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_inj(perc):\n",
    "    db = (\n",
    "        pd.read_parquet(\n",
    "            INJ_FPATH,\n",
    "            filters=[(\"PERC\", \"==\", perc), (\"ID\", \"not in\", DROPPED_IDS[perc])],\n",
    "            columns=[\n",
    "                \"Head_HIC15\",\n",
    "                \"Head_a3ms\",\n",
    "                \"Neck_My_Extension\",\n",
    "                \"Neck_Fz_Max_Tension\",\n",
    "                \"Neck_Fx_Shear_Max\",\n",
    "                \"Chest_Deflection\",\n",
    "                \"Femur_Fz_Max_Compression\",\n",
    "                \"Chest_VC\",\n",
    "                \"Chest_a3ms\",\n",
    "            ],\n",
    "        )\n",
    "        .droplevel(\"PERC\")\n",
    "        .astype(np.float32)\n",
    "    )\n",
    "    db_med_ = db.median(axis=0)\n",
    "    db_med = ((db.copy() * 0) + 1) * db_med_\n",
    "\n",
    "    sc = pd.Series(r2_score(db, db_med, multioutput=\"raw_values\"), index=db.columns)\n",
    "    display(pd.DataFrame({\"Value\":db_med_, \"R2\":sc}))\n",
    "\n",
    "\n",
    "eval_inj(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_inj(95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_class(displ=True):\n",
    "    rel_cols = [\n",
    "        \"Head_HIC15\",\n",
    "        \"Head_a3ms\",\n",
    "        \"Neck_My_Extension\",\n",
    "        \"Neck_Fz_Max_Tension\",\n",
    "        \"Neck_Fx_Shear_Max\",\n",
    "        \"Chest_Deflection\",\n",
    "        \"Chest_VC\",\n",
    "        \"Femur_Fz_Max_Compression\",\n",
    "    ]\n",
    "    n_classess = (2, 3, 5, 7)\n",
    "    db = defaultdict(dict)\n",
    "    for n_classes in n_classess:\n",
    "        for perc in [5, 95]:\n",
    "            db_ = (\n",
    "                pd.read_parquet(\n",
    "                    CLASSES_FPATHS[n_classes],\n",
    "                    filters=[(\"PERC\", \"==\", perc), (\"ID\", \"not in\", DROPPED_IDS[perc])],\n",
    "                    columns=rel_cols,\n",
    "                )\n",
    "                .droplevel(\"PERC\")\n",
    "                .astype(np.int32)[rel_cols]\n",
    "            )\n",
    "\n",
    "            clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "            clf.fit(db_[rel_cols], db_[rel_cols])\n",
    "            y_pred = pd.DataFrame(clf.predict(db_), index=db_.index, columns=rel_cols)\n",
    "\n",
    "            modes = [clf.classes_[i][np.argmax(clf.class_prior_[i])] for i in range(len(clf.classes_))]\n",
    "\n",
    "            db[n_classes][perc] = pd.DataFrame(\n",
    "                {\n",
    "                    \"Mode\": modes,\n",
    "                    \"Frequency\": [np.max(x) for x in clf.class_prior_],\n",
    "                    \"F1\": [\n",
    "                        f1_score(\n",
    "                            db_[c],\n",
    "                            y_pred[c],\n",
    "                            average=\"weighted\",\n",
    "                            labels=list(range(n_classes)),\n",
    "                            zero_division=0.0,\n",
    "                        )\n",
    "                        for c in rel_cols\n",
    "                    ],\n",
    "                },\n",
    "                index=rel_cols,\n",
    "            )\n",
    "\n",
    "            if displ:\n",
    "                print(n_classes, perc)\n",
    "                display(db[n_classes][perc].loc[rel_cols])\n",
    "\n",
    "    if not displ:\n",
    "        for idx in rel_cols:\n",
    "            print(\"#\" * 5, idx, \"#\" * 5)\n",
    "            for n_classes in n_classess:\n",
    "                full_str = f\"{n_classes:1d}\"\n",
    "                for perc in [5, 95]:\n",
    "                    full_str += \" & \"\n",
    "                    full_str += \" & \".join(\n",
    "                        [str(int(x)) if i == 0 else f\"{np.floor(x*100)/100:.2f}\" for i, x in enumerate(db[n_classes][perc].loc[idx].values)]\n",
    "                    )\n",
    "\n",
    "                print(full_str)\n",
    "\n",
    "\n",
    "eval_class(displ=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_class_conf(n_classes: int, perc: int, col: str):\n",
    "    rel_cols = [\n",
    "        \"Head_HIC15\",\n",
    "        \"Head_a3ms\",\n",
    "        \"Neck_My_Extension\",\n",
    "        \"Neck_Fz_Max_Tension\",\n",
    "        \"Neck_Fx_Shear_Max\",\n",
    "        \"Chest_Deflection\",\n",
    "        \"Chest_VC\",\n",
    "        \"Femur_Fz_Max_Compression\",\n",
    "    ]\n",
    "\n",
    "    db_ = (\n",
    "        pd.read_parquet(\n",
    "            CLASSES_FPATHS[n_classes],\n",
    "            filters=[(\"PERC\", \"==\", perc), (\"ID\", \"not in\", DROPPED_IDS[perc])],\n",
    "            columns=[col],\n",
    "        )\n",
    "        .droplevel(\"PERC\")\n",
    "        .astype(np.int32)\n",
    "    )\n",
    "\n",
    "    clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "    clf.fit(db_, db_)\n",
    "    y_pred = pd.DataFrame(clf.predict(db_), index=db_.index, columns=[col])\n",
    "    print(clf.classes_)\n",
    "\n",
    "    conf = confusion_matrix(db_[col], y_pred[col], labels=list(range(n_classes)))\n",
    "    conf = pd.DataFrame(\n",
    "        conf,\n",
    "        index=[f\"True {x}\" for x in range(n_classes)],\n",
    "        columns=[f\"Pred {x}\" for x in range(n_classes)],\n",
    "    )\n",
    "    display(conf)\n",
    "\n",
    "\n",
    "eval_class_conf(n_classes=3, perc=5, col=\"Femur_Fz_Max_Compression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_intervals(chs, perc: int):\n",
    "    f_width = 448.13095 / 72 - 0.2\n",
    "    fig, ax = plt.subplot_mosaic(mosaic=[[\"L\"]*len(chs), chs], layout=\"constrained\", height_ratios=[0.1,1])\n",
    "\n",
    "    for i, ch in enumerate(chs):\n",
    "        db = pd.read_parquet(\n",
    "            CHANNELS_FPATH,\n",
    "            columns=[ch],\n",
    "            filters=[(\"PERC\", \"==\", perc), (\"ID\", \"not in\", DROPPED_IDS[perc])],\n",
    "        ).droplevel(\"PERC\")\n",
    "        print(len(set(db.index.get_level_values(STR.id))))\n",
    "        db = db.groupby(\"TIME\").quantile([0.25, 0.5, 0.75])\n",
    "        db.index.set_names([\"TIME\", \"Quantile\"], inplace=True)\n",
    "        db = db[ch].unstack(\"Quantile\")\n",
    "\n",
    "        ax[ch].plot(db.index, db[0.5], label=\"Median\")\n",
    "        ax[ch].fill_between(db.index, db[0.25], db[0.75], alpha=0.3, label=\"IQR\")\n",
    "        ax[ch].grid()\n",
    "        [ax[ch].axvline(v, c=\"black\", ls=\"--\", label=\"Zone of Interest\" if v==60 else \"\") for v in (60, 120)]\n",
    "        ax[ch].set_xlabel(\"Time [ms]\")\n",
    "        ax[ch].set_ylabel(ch.replace(\"OCCU\", f\"H3{perc:02d}\"), {\"fontname\": \"CMU Typewriter Text\", \"fontsize\": \"large\", \"fontweight\": \"bold\"})\n",
    "    ax[\"L\"].legend(*ax[chs[0]].get_legend_handles_labels(), loc=\"upper center\", ncols=3)\n",
    "    ax[\"L\"].axis(\"off\")\n",
    "\n",
    "    fig.set_figheight(0.35 * f_width)\n",
    "    fig.set_figwidth(f_width)\n",
    "    fig.savefig(FIG_DIR / f\"intervals_{perc}.pdf\")\n",
    "\n",
    "\n",
    "conv_intervals(chs=[\"03HEAD0000OCCUACRD\", \"03NECKUP00OCCUMOYD\"], perc=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_channel(perc:int):\n",
    "        db = pd.read_parquet(\n",
    "            CHANNELS_FPATH,\n",
    "            # columns=[ch],\n",
    "            filters=[(\"PERC\", \"==\", perc), (\"ID\", \"not in\", DROPPED_IDS[perc])],\n",
    "        ).droplevel(\"PERC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_resampler(chs: List[str], perc: int, n_stps: List[int], sid: int):\n",
    "    f_path = Path(\"data\") / \"doe\" / \"doe_sobol_20240705_194200\" / \"channels.parquet\"\n",
    "    a = Data()\n",
    "    a.set_from_files(file_paths=[f_path], percentiles=[perc], idxs=[sid], columns=chs)\n",
    "\n",
    "    f_width = 448.13095 / 72 - 0.2\n",
    "    fig, ax = plt.subplot_mosaic(mosaic=([[\"L\"] * len(chs), chs]), layout=\"constrained\", height_ratios=[0.1, 1])\n",
    "    ls = [\"-\", \"--\", \"-.\", \":\"]\n",
    "\n",
    "    for j, n_tsp in enumerate(reversed(n_stps)):\n",
    "        db: pd.DataFrame = a.get_temporal_resampled(n_tsp)\n",
    "        for i, ch in enumerate(chs):\n",
    "            ax[ch].plot(\n",
    "                db.index.get_level_values(STR.time),\n",
    "                db[ch],  # - 10 * j,\n",
    "                label=f\"{'Reference with' if n_tsp == 1400 else 'Resampled to'} {n_tsp/140:.1f} kHz\",\n",
    "                # marker=\"o\",\n",
    "                # markersize=1,\n",
    "                # alpha=0.5,\n",
    "                linewidth=2,\n",
    "                ls=ls[j]\n",
    "            )\n",
    "\n",
    "            if j == 0:\n",
    "                ax[ch].set_xlabel(\"Time [ms]\")\n",
    "                ax[ch].set_ylabel(ch.replace(\"OCCU\", f\"H3{perc:02d}\"), {\"fontname\": \"CMU Typewriter Text\", \"fontsize\": \"large\", \"fontweight\": \"bold\"})\n",
    "                ax[ch].grid()\n",
    "    ax[\"L\"].legend(*ax[chs[0]].get_legend_handles_labels(), ncol=2, loc=\"upper center\")\n",
    "    ax[\"L\"].axis(\"off\")\n",
    "\n",
    "    fig.set_figheight(0.4 * f_width)\n",
    "    fig.set_figwidth(f_width)\n",
    "    fig.savefig(FIG_DIR / f\"resampling_{perc}.pdf\")\n",
    "\n",
    "\n",
    "plot_resampler(chs=[\"03HEAD0000OCCUACRD\", \"03NECKUP00OCCUMOYD\"], perc=95, n_stps=[10, 28, 70, 1400], sid=66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
